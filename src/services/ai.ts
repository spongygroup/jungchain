/**
 * AI ì„œë¹„ìŠ¤ â€” Gemini ê¸°ë°˜ ìŠ¤í† ë¦¬/ìº¡ì…˜/ë²ˆì—­/ê²€ì¦ + OpenAI Whisper STT
 */
import { GoogleGenerativeAI } from '@google/generative-ai';
import OpenAI, { toFile } from 'openai';
import { config, getCity, TZ_LANGUAGES } from '../config.js';

const genAI = new GoogleGenerativeAI(config.googleApiKey);

function getModel(modelName?: string) {
  return genAI.getGenerativeModel({ model: modelName ?? 'gemini-2.5-pro' });
}

// â”€â”€â”€ Story relay: generate next chapter with choices â”€â”€â”€
const CHOICE_FORMAT = `
í˜•ì‹:
1. ì´ì „ ì„ íƒì§€ê°€ ìˆìœ¼ë©´ í•˜ë‚˜ë¥¼ ê³¨ë¼ì„œ ì‹œì‘
2. ìŠ¤í† ë¦¬ë¥¼ 150~300ìë¡œ ì „ê°œ (ë°°ê²½ ë¬˜ì‚¬ ìµœì†Œí™”, ì•¡ì…˜/ëŒ€í™”/ê°ì • ìœ„ì£¼)
3. ë§ˆì§€ë§‰ì— ì„ íƒì§€ 2ê°œ ì œì‹œ

ì¶œë ¥ í˜•ì‹:
[ì„ íƒ: A ë˜ëŠ” B] (ì´ì „ ì„ íƒì§€ê°€ ìˆì„ ë•Œë§Œ)

(ìŠ¤í† ë¦¬ ë³¸ë¬¸ 150~300ì)

A) (ì„ íƒì§€ 1)
B) (ì„ íƒì§€ 2)`;

export async function generateStoryBlock(
  previousBlocks: string[],
  offset: number,
  isFirst: boolean = false,
  isLast: boolean = false,
): Promise<string> {
  const model = getModel();
  const city = getCity(offset);
  const lang = TZ_LANGUAGES[offset] ?? 'English';
  const context = previousBlocks.slice(-5).join('\n');

  let systemPrompt: string;
  let userPrompt: string;

  if (isFirst) {
    systemPrompt = `You are a novelist from ${city}. Write the opening scene of a relay novel.
- Write in ${lang}
- Romance/thriller genre. Hook the reader immediately.
- 150-300 characters. Minimal scenery, focus on action/dialogue.
- End with 2 choices (A/B)`;
    userPrompt = `Start the relay novel from ${city}. Strong opening + 2 choices.`;
  } else if (isLast) {
    systemPrompt = `ë„ˆëŠ” ${city}ì˜ ì‘ê°€ì•¼. ë¦´ë ˆì´ ì†Œì„¤ì˜ ë§ˆì§€ë§‰ ì¥ë©´ì„ ì¨.
- ${lang}(ìœ¼)ë¡œ
- ì´ì „ ì„ íƒì§€ ì¤‘ í•˜ë‚˜ë¥¼ ê³¨ë¼ ì‹œì‘
- ê°ë™ì ì¸ ê²°ë§. ì—¬ìš´ì´ ë‚¨ê²Œ.
- 150~300ì. ì„ íƒì§€ ì—†ì´ ë§ˆë¬´ë¦¬.`;
    userPrompt = `ë¦´ë ˆì´ ì†Œì„¤:\n${context}\n\nê²°ë§ì„ ì¨ì¤˜. ì„ íƒì§€ ì—†ì´ ë§ˆë¬´ë¦¬.`;
  } else {
    systemPrompt = `ë„ˆëŠ” ë¦´ë ˆì´ ì†Œì„¤ì— ì°¸ì—¬í•˜ëŠ” ${city}ì˜ ì‘ê°€ì•¼.
- ë°˜ë“œì‹œ ${lang}(ìœ¼)ë¡œ ì¨
- ì´ì „ ìŠ¤í† ë¦¬ë¥¼ ì½ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€
- ë„ˆì˜ ë„ì‹œ/ë¬¸í™”ì  ìš”ì†Œë¥¼ ë…¹ì—¬
- ë°°ê²½ ë¬˜ì‚¬ ìµœì†Œí™”. ëŒ€í™”, ì•¡ì…˜, ê°ì •, ë°˜ì „ ìœ„ì£¼.
${CHOICE_FORMAT}`;
    userPrompt = `ë¦´ë ˆì´ ì†Œì„¤ ì§„í–‰ ì¤‘:\n${context}\n\n${lang}(ìœ¼)ë¡œ ì´ì–´ì¨ì¤˜.`;
  }

  try {
    const result = await model.generateContent({
      systemInstruction: systemPrompt,
      contents: [{ role: 'user', parts: [{ text: userPrompt }] }],
    });
    return result.response.text()?.trim() || '...';
  } catch (err: any) {
    console.error(`AI story generation error: ${err.message}`);
    return '(ì´ì•¼ê¸°ê°€ ì¡°ìš©íˆ ì´ì–´ì§‘ë‹ˆë‹¤...)';
  }
}

// â”€â”€â”€ Translate relay content (with in-memory cache) â”€â”€â”€
const translateCache = new Map<string, string>();

export async function translateContent(
  content: string[],
  targetLang: string,
): Promise<string> {
  if (content.length === 0) return '';
  const text = content.join('\n');
  const cacheKey = `${targetLang}::${text}`;
  const cached = translateCache.get(cacheKey);
  if (cached) return cached;

  const model = getModel('gemini-2.0-flash');

  try {
    const result = await model.generateContent({
      systemInstruction: `ë„ˆëŠ” ë²ˆì—­ê°€ì•¼. ë¦´ë ˆì´ ì½˜í…ì¸ ë¥¼ ${targetLang}(ìœ¼)ë¡œ ë²ˆì—­í•´ì¤˜.
- ì›ë¬¸ì˜ ëŠë‚Œê³¼ ë‰˜ì•™ìŠ¤ë¥¼ ì‚´ë ¤ì„œ
- ê° ë¸”ë¡ êµ¬ë¶„ ìœ ì§€
- ë²ˆì—­ë§Œ ì¶œë ¥. ì„¤ëª… ì—†ì´.`,
      contents: [{ role: 'user', parts: [{ text: `ë‹¤ìŒì„ ${targetLang}(ìœ¼)ë¡œ ë²ˆì—­í•´ì¤˜:\n\n${text}` }] }],
    });
    const translated = result.response.text().trim();
    translateCache.set(cacheKey, translated);
    return translated;
  } catch (err: any) {
    console.error(`Translation error: ${err.message}`);
    return `(ë²ˆì—­ ì‹¤íŒ¨)\n${text}`;
  }
}

// â”€â”€â”€ Photo validation (mission + safety) â”€â”€â”€
export async function validatePhoto(
  photoBase64: string,
  mission: string,
): Promise<{ status: 'pass' | 'mission_fail' | 'safety_fail'; description: string; userMessage: string; jungzigiComment: string }> {
  const model = getModel('gemini-2.0-flash');

  try {
    const result = await model.generateContent({
      systemInstruction: `You are a photo validator for a fun photo relay game. Check TWO things:

1. SAFETY CHECK (strict):
   - Personal info visible? (ID cards, credit cards, documents, license plates)
   - Faces clearly identifiable? (close-up portraits â€” crowd/distant faces OK)
   - NSFW content?
   If ANY safety issue: status="safety_fail"

2. MISSION CHECK (lenient):
   - Does the photo reasonably match the mission?
   - Be generous â€” creative interpretations welcome!
   If doesn't match: status="mission_fail"

3. If both pass: status="pass"

Respond ONLY in JSON:
{
  "status": "pass" | "mission_fail" | "safety_fail",
  "description": "brief description in English",
  "userMessage": "friendly message to user in their language (1-2 sentences, casual, warm)",
  "jungzigiComment": "a warm, personal 1-sentence comment about the photo in the user's language â€” like a friend reacting to the photo (e.g. 'ì™€ ì´ ë¹› ì§„ì§œ ì˜ˆì˜ë‹¤!', 'That sky is amazing! ğŸŒ…'). Be genuine, specific to what you see."
}`,
      contents: [{
        role: 'user',
        parts: [
          { text: `Mission: "${mission}"\nValidate this photo:` },
          { inlineData: { mimeType: 'image/jpeg', data: photoBase64 } },
        ],
      }],
    });

    const raw = result.response.text().trim();
    const json = JSON.parse(raw.replace(/```json?\n?/g, '').replace(/```/g, ''));
    return json;
  } catch (err: any) {
    console.error(`Photo validation error: ${err.message}`);
    return { status: 'pass', description: 'validation skipped', userMessage: 'í™•ì¸ ì™„ë£Œ!', jungzigiComment: 'ì¢‹ì€ ì‚¬ì§„ì´ë„¤ìš”! ğŸ“¸' };
  }
}

// â”€â”€â”€ Generate photo via Imagen 4 â”€â”€â”€
export async function generatePhoto(
  prompt: string,
  aspectRatio: string = '9:16',
): Promise<string | null> {
  const apiKey = config.googleApiKey;
  const url = `https://generativelanguage.googleapis.com/v1beta/models/imagen-4.0-generate-preview-06-06:predict?key=${apiKey}`;

  try {
    const res = await fetch(url, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        instances: [{ prompt }],
        parameters: { sampleCount: 1, aspectRatio },
      }),
    });
    const data = await res.json() as any;
    return data.predictions?.[0]?.bytesBase64Encoded ?? null;
  } catch (err: any) {
    console.error(`Imagen 4 error: ${err.message}`);
    return null;
  }
}

// â”€â”€â”€ Generate photo caption/description â”€â”€â”€
export async function generatePhotoCaption(
  offset: number,
  mission: string,
  previousCaption: string | null,
  style: string,
): Promise<string> {
  const model = getModel('gemini-2.0-flash');
  const city = getCity(offset);
  const lang = TZ_LANGUAGES[offset] ?? 'English';

  try {
    const result = await model.generateContent({
      systemInstruction: `ë„ˆëŠ” ${city}ì— ì‚¬ëŠ” ì‚¬ëŒì´ì•¼. í¬í†  ë¦´ë ˆì´ì— ì°¸ì—¬ ì¤‘.
- ${lang}(ìœ¼)ë¡œ ì¨
- ìŠ¤íƒ€ì¼: ${style}
- ì‚¬ì§„ ë¯¸ì…˜: ${mission}
- ìºì£¼ì–¼í•˜ê³  ì§§ê²Œ (1-2ë¬¸ì¥)
- í•´ì‹œíƒœê·¸ ì—†ì´`,
      contents: [{
        role: 'user',
        parts: [{ text: previousCaption ? `ì´ì „ ìº¡ì…˜: "${previousCaption}"\n\n${city}ì—ì„œ ì°ì€ ì‚¬ì§„ ìº¡ì…˜ì„ ì¨ì¤˜.` : `${city}ì—ì„œ ì°ì€ ì‚¬ì§„ ìº¡ì…˜ì„ ì¨ì¤˜.` }],
      }],
    });
    return result.response.text().trim();
  } catch {
    return `ğŸ“ ${city}`;
  }
}

// â”€â”€â”€ Content validation (Gemini Flash) â”€â”€â”€
export async function validateText(text: string): Promise<{ safe: boolean; reason?: string }> {
  try {
    const model = getModel('gemini-2.0-flash');
    const result = await model.generateContent({
      contents: [{ role: 'user', parts: [{ text:
        `ë‹¤ìŒ í…ìŠ¤íŠ¸ê°€ ì•ˆì „í•œì§€ íŒë‹¨í•´ì¤˜. ì°¨ë‹¨ ê¸°ì¤€: í˜ì˜¤/ì°¨ë³„, ì„±ì  ì½˜í…ì¸ , í­ë ¥ ì„ ë™, ê°œì¸ì •ë³´ ë…¸ì¶œ. ì¼ìƒì ì¸ í‘œí˜„ì´ë‚˜ ê°€ë²¼ìš´ ìš•ì„¤ì€ í—ˆìš©.
JSONìœ¼ë¡œë§Œ ë‹µí•´: {"safe": true} ë˜ëŠ” {"safe": false, "reason": "ì‚¬ìœ "}

í…ìŠ¤íŠ¸: "${text}"` }] }],
    });
    const json = result.response.text().trim().replace(/```json\n?|\n?```/g, '');
    return JSON.parse(json);
  } catch {
    return { safe: true }; // fail-open
  }
}

// â”€â”€â”€ Voice transcription via OpenAI Whisper â”€â”€â”€
export async function transcribeVoice(audioBuffer: Buffer): Promise<string> {
  const model = getModel('gemini-2.0-flash');
  const base64Audio = audioBuffer.toString('base64');

  try {
    const result = await model.generateContent({
      systemInstruction: 'You are a speech-to-text transcriber. Transcribe the audio exactly as spoken. Output ONLY the transcription text, nothing else. If the audio is unclear or empty, output an empty string.',
      contents: [{
        role: 'user',
        parts: [
          { text: 'Transcribe this audio:' },
          { inlineData: { mimeType: 'audio/ogg', data: base64Audio } },
        ],
      }],
    });
    return result.response.text().trim();
  } catch (err: any) {
    console.error(`Gemini STT error: ${err.message}`);
    return '';
  }
}
